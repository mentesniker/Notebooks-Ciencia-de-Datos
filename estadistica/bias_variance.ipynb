{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "bias_variance.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDnDGkZk9VYd"
      },
      "source": [
        "### Intercambio sesgo-varianza (bias-variance tradeoff)\n",
        "\n",
        "#### Sesgo\n",
        "\n",
        "Cuando generamos conclusiones a partir de un modelo ajustado a cierto conjunto de datos podemos encontrarnos en una de dos situaciones. La primera involucra que tratemos de medir o evaluar qué tan bien se ajustan los datos a un modelo teórico previo, este \"ajuste de los datos\" concretamente se vuelve en qué tan bien los parámetros muestrales que estemos proponiendo se ajustan al parámetro poblacional real. Esta desviación es conocida como sesgo y su definición es la siguiente:\n",
        "\n",
        "$$Sesgo~de~un~estimador~\\hat\\theta_n: E[\\hat\\theta_n]-\\theta$$\n",
        "\n",
        "en ésta, se tiene que estamos tratando de estimar el valor de un parámetro poblacional $\\theta$ a partir de la esperanza de varios parámetros muestrales $\\hat\\theta$ correspondientes cada una a una muestra particular de tamaño $n$. Esta cantidad surge dentro del enfoque de la estadística inferencial clásica o paramétrica, en donde se tiene una distribución teórica de referencia para los datos y se busca evaluar qué tanto los parámetros estimados se desvían de \"los que deberían ser\" los valores de los parámetros reales.\n",
        "\n",
        "En un caso ideal lo que pretenderíamos es que el estimador que estamos utilizando tenga un sesgo pequeño o tendiente a cero. Ya que si podemos probar esto teóricamente entonces podemos confiar en que si nuestros datos sí se distribuyen de la manera en que estamos suponiendo encontraremos un buen valor para el estimador del valor real del parámetro poblacional.\n",
        "\n",
        "#### Riesgo (riesgo cuadrático)\n",
        "\n",
        "Sin embargo, en la práctica el elegir un estimador insesgado (*i.e.* con sesgo 0) no suele garantizar una buena estimación. Por ejemplo, podríamos elegir un valor constante como estimador. Éste ejercicio aunque trivial acarrea como consecuencia que nuestro estimador tenga una varianza de cero, sin embargo su sesgo es tanto como la diferencia entre su valor y el parámetro real $\\theta$. Por otra parte podemos elegir a la esperanza del conjunto de datos como estimador y aunque su sesgo tiende a cero, si el tamaño de muestra no es \"lo suficientemente grande\" o el muestreo no fue \"representativo\", nos arriesgamos a tener valores de varianza grandes. Es entonces que podemos considerar el riesgo o riesgo cuadrático de un estimador $\\hat\\theta_n$, como una medida que nos permita cuantificar ambos escenarios.\n",
        "\n",
        "El riesgo cuadrático se define de la siguiente manera:\n",
        "\n",
        "$$Riesgo^2~de~un~estimador~\\hat\\theta_n: E[(\\hat\\theta_n-\\theta)^2]$$\n",
        "\n",
        "Haciendo un poco de álgebra:\n",
        "\n",
        "$$Riesgo^2=E[(\\hat\\theta_n-\\theta)^2]=E[\\hat\\theta_n^2]+\\theta^2-2E[\\hat\\theta_n]\\theta$$ \n",
        "\n",
        "$$Sesgo^2=(E[\\hat\\theta_n]-\\theta)^2=E[\\hat\\theta_n]^2+\\theta^2-2E[\\hat\\theta_n]\\theta$$\n",
        "\n",
        "$$Varianza=E[\\hat\\theta_n^2]-E[\\hat\\theta_n]^2$$\n",
        "\n",
        "$$Riesgo^2=Sesgo^2+Varianza$$\n",
        "\n",
        "**OBSERVACIÓN:** El  $Riesgo^2$  es equivalente a definir el $Error~Cuadrático~Promedio$ $(MSE)$ de un estimador $\\hat\\theta_n$.\n",
        "\n",
        "Los posibles escenarios pueden ser:\n",
        "\n",
        "![](bias_variance.jpeg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ii5Hrdh9VYg",
        "outputId": "bd89ed67-5e32-4cef-861d-4a781e1368e0"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "dataframe = read_csv(url, header=None)\n",
        "dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
              "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
              "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
              "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
              "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
              "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
              "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
              "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
              "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
              "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
              "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
              "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
              "\n",
              "         11    12    13  \n",
              "0    396.90  4.98  24.0  \n",
              "1    396.90  9.14  21.6  \n",
              "2    392.83  4.03  34.7  \n",
              "3    394.63  2.94  33.4  \n",
              "4    396.90  5.33  36.2  \n",
              "..      ...   ...   ...  \n",
              "501  391.99  9.67  22.4  \n",
              "502  396.90  9.08  20.6  \n",
              "503  396.90  5.64  23.9  \n",
              "504  393.45  6.48  22.0  \n",
              "505  396.90  7.88  11.9  \n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YXk_gD59VYi"
      },
      "source": [
        "Attribute Information:\n",
        "\n",
        "    1. CRIM      per capita crime rate by town\n",
        "    2. ZN        proportion of residential land zoned for lots over \n",
        "                 25,000 sq.ft.\n",
        "    3. INDUS     proportion of non-retail business acres per town\n",
        "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
        "                 river; 0 otherwise)\n",
        "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
        "    6. RM        average number of rooms per dwelling\n",
        "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
        "    8. DIS       weighted distances to five Boston employment centres\n",
        "    9. RAD       index of accessibility to radial highways\n",
        "    10. TAX      full-value property-tax rate per $10,000\n",
        "    11. PTRATIO  pupil-teacher ratio by town\n",
        "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
        "                 by town\n",
        "    13. LSTAT    % lower status of the population\n",
        "    14. MEDV     Median value of owner-occupied homes in $1000's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wcAskeE9VYj",
        "outputId": "eec4574a-549a-4a03-dfa0-2e6db836b666"
      },
      "source": [
        "### Adjusting linear model\n",
        "# separate into inputs and outputs\n",
        "data = dataframe.values\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# define the model\n",
        "model = LinearRegression()\n",
        "# estimate bias and variance\n",
        "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
        "# summarize results\n",
        "print('MSE: %.3f' % mse)\n",
        "print('Bias: %.3f' % bias)\n",
        "print('Variance: %.3f' % var)\n",
        "bias/var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 22.418\n",
            "Bias: 20.744\n",
            "Variance: 1.674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.39232538754308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEh7S3V-9VYj",
        "outputId": "3d26f71f-3a5e-42a3-a81f-115e58196dab"
      },
      "source": [
        "# Adjusting linear model over scaled data\n",
        "# scaling data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(dataframe)\n",
        "data = data_scaled\n",
        "# separate into inputs and outputs\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# define the model\n",
        "model = LinearRegression()\n",
        "# estimate bias and variance\n",
        "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
        "# summarize results\n",
        "print('MSE: %.3f' % mse)\n",
        "print('Bias: %.3f' % bias)\n",
        "print('Variance: %.3f' % var)\n",
        "bias/var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.011\n",
            "Bias: 0.010\n",
            "Variance: 0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.392325387543028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XacWNE1C9VYk",
        "outputId": "50190ca1-2004-4189-b6df-6522f5f0eae6"
      },
      "source": [
        "# Adjusting k nearest neighbors\n",
        "rmse_val = [] #to store rmse values for different k\n",
        "for K in range(20):\n",
        "    K = K+1\n",
        "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
        "\n",
        "    model.fit(X_train, y_train)  #fit the model\n",
        "    pred=model.predict(X_test) #make prediction on test set\n",
        "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
        "    rmse_val.append(error) #store rmse values\n",
        "    print('RMSE value for k= ' , K , 'is:', error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value for k=  1 is: 0.12329595496719975\n",
            "RMSE value for k=  2 is: 0.08990828475358655\n",
            "RMSE value for k=  3 is: 0.09370807343045032\n",
            "RMSE value for k=  4 is: 0.09819941375277315\n",
            "RMSE value for k=  5 is: 0.10066900045616058\n",
            "RMSE value for k=  6 is: 0.1059645905547054\n",
            "RMSE value for k=  7 is: 0.10701778052847595\n",
            "RMSE value for k=  8 is: 0.1096279187456035\n",
            "RMSE value for k=  9 is: 0.1129961695383228\n",
            "RMSE value for k=  10 is: 0.11610742369044125\n",
            "RMSE value for k=  11 is: 0.11838902182196599\n",
            "RMSE value for k=  12 is: 0.1176068493024546\n",
            "RMSE value for k=  13 is: 0.11675037879516546\n",
            "RMSE value for k=  14 is: 0.11695805616580658\n",
            "RMSE value for k=  15 is: 0.1188447251757602\n",
            "RMSE value for k=  16 is: 0.11939981507749975\n",
            "RMSE value for k=  17 is: 0.12172056535594623\n",
            "RMSE value for k=  18 is: 0.12384003279010838\n",
            "RMSE value for k=  19 is: 0.12517898581470946\n",
            "RMSE value for k=  20 is: 0.1266423976703934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDdIyZZN9VYl",
        "outputId": "5616bff0-c281-4193-914b-7826900d9fc1"
      },
      "source": [
        "# small values, such as k=1, result in a low bias and a high variance, \n",
        "# whereas large k values, such as k=21, result in a high bias and a low variance.\n",
        "model = neighbors.KNeighborsRegressor(n_neighbors = 2)\n",
        "# estimate bias and variance\n",
        "mse, bias, var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
        "# summarize results\n",
        "print('MSE: %.3f' % mse)\n",
        "print('Bias: %.3f' % bias)\n",
        "print('Variance: %.3f' % var)\n",
        "bias/var"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.013\n",
            "Bias: 0.008\n",
            "Variance: 0.005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.487357868553737"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_7R1JIa9VYl"
      },
      "source": [
        "### ¿Qué elegir o qué hacer?\n",
        "\n",
        "Lo que nosotros deseamos idealmente son modelos con bajo sesgo y baja varianza, ya que esto implicará un menor riesgo cuadrático (error cuadrático promedio). En realidad esto describe de manera bastante concisa la meta del aprendizaje de máquina aplicado; sin embargo, la realidad es que suele presentarse un *tradeoff* entre ambas medidas.\n",
        "\n",
        "Un modelo con alto sesgo hace supuestos fuertes sobre la función subyaciente (desconocida) que funge como mapeo entre los predictores y las variables de respuesta del dataset en cuestión, tal es el caso de los modelos lineales. Por otra parte un modelo con alta varianza es un modelo que depende fuertemente de la naturaleza específica del conjunto de entrenamiento utilizado para entrenar al modelo, tal es el caso de los árboles de decisión sin poda.\n",
        "\n",
        "En otras palabras, modelos \"simples\" como la regresión lineal o logística suelen presentar un alto sesgo y una baja varianza. Es decir, podemos utilizar distintos conjuntos de entrenamiento y el nivel de ajuste del modelo seguirá siendo más o menos el mismo. \n",
        "\n",
        "Por otra parte, modelos \"más complejos\", como los árboles de decisión, suelen tener un sesgo bajo y una varianza alta, lo cual puede constatarse al modificar el conjunto de entrenamiento y comparar la calidad del ajuste logrado en cada escenario.\n",
        "\n",
        "Existen también modelos que pueden presentar un sesgo bajo y una alta varianza bajo ciertos valores para los parámetros de inicialización y un alto sesgo y baja varianza para otros. Ejemplo de esto es KNN, ya que si elegimos una valor de $k=1$ el sesgo es prácticamente nulo mientras que la varianza de las predicciones aumenta, y cuando elegimos $k=21$ esto resulta en un alto sesgo y una baja varianza.\n",
        "\n",
        "Por lo tanto, una regla de dedo para decidir entre aumentar o disminuir el sesgo o la varianza de un modelo, siempre y cuando contemos con parámetros modificables que afecten esto, será que utilicemos como criterio de comparación el efecto conjunto que tienen ambas medidas sobre el valor del riesgo cuadrático del estimador (error cuadrático promedio), eligiendo aquella combinación de sesgo-varianza que minimice esta medida."
      ]
    }
  ]
}